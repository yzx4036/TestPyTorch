{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4664d535",
   "metadata": {},
   "source": [
    "# Double Deep Q-Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4852c4",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "- [1 - Motivation](#1)\n",
    "- [2 - Example](#2)\n",
    "- [3 - Application to Deep Q-Learning](#3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e48d85a",
   "metadata": {},
   "source": [
    "Full paper: [Deep Reinforcement Learning with Double Q-Learning (2015)](https://arxiv.org/pdf/1509.06461.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c680199c",
   "metadata": {},
   "source": [
    "<a name='1'></a>\n",
    "# 1 - Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a34c5a",
   "metadata": {},
   "source": [
    "Conventional Q-Learning is affected by an overestimation bias, due to the maximization step performed for the bootstrap target. This can harm learning as illustrated in figure 1.\n",
    "\n",
    "<img src=\"images/overestimation_dqn.png\">\n",
    "<caption><center><font ><b>Figure 1</b>: Overestimation by DQN </center></caption>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ef3ef0",
   "metadata": {},
   "source": [
    "<a name='2'></a>\n",
    "# 2 - Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a348fd97",
   "metadata": {},
   "source": [
    "**Problem understanding**\n",
    "\n",
    "Lets say there are 100 people with a equal true weight of 150 lbs. We have a weighing scale that is off by +/- 1 lb. We measure person 1's weight and store it in $X^1$, person 2's weight in $X^2$, and so on.\n",
    "    \n",
    "Let's calculate $Y=\\max_{i} X^i$.\n",
    "    \n",
    "At noise 0, Y is equal to 150 lbs, but as the measurement noise increases, Y will increase too. So under noise, the maximum value is biased to be larger than it should be.\n",
    "\n",
    "**Solution**\n",
    "\n",
    "Let's focus on a idea to solve this problem. \n",
    "    \n",
    "Measure each person's weight twice (independent noise): $X_{1}^i and X_{2}^i$. \n",
    "\n",
    "Then set \n",
    "$$n = argmax_{i} X_{1}^i$$ \n",
    "$$Y = X_{2}^n$$\n",
    "    \n",
    "Where n is the index corresponding to the person with the highest first measurement of weight. To estimate the max you now take that same person's second weight. This new estimate of the max is now robust to noise. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d65b98",
   "metadata": {},
   "source": [
    "<a name='3'></a>\n",
    "# 3 - Application to Deep Q-Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c719ff0e",
   "metadata": {},
   "source": [
    "Double Q-Learning addresses the overestimation problem by appyling the idea above. The key idea is to decouple the selection of the action from its evaluation in the maximization performed for the bootstrap target. This change was shown to reduce harmful overestimations that were present for DQN, thereby improving performance. In Double Q-Learning the loss is calculated using:\n",
    "\n",
    "$$(R_{t+1} + \\gamma_{t+1} q_{\\theta'}(S_{t+1}, \\max_{a'}q_{\\theta}(S_{t+1}, a')) - q_{\\theta}(S_{t}, A_{t}))²$$\n",
    "\n",
    "instead of $$(R_{t+1} + \\gamma_{t+1} \\max_{a'}q_{\\theta'}(S_{t+1}, a')) - q_{\\theta}(S_{t}, A_{t}))²$$\n",
    "    \n",
    "In other words: We find the index of the highest Q-value from the first network $Q_{\\theta_{1}}$ and use that index to obtain the action from the second network $Q_{\\theta_{2}}$. Note that this idea is independent of the target network trick to avoid shifting targets.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
